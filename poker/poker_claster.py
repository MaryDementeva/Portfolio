# -*- coding: utf-8 -*-
"""poker_claster.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J4tmTFGu2AkHRm2VVwGYI8WIp4Ybttes

**Описание**  
Обрабатываются данные из датафрейма, полученного в файле poker.ipnb
"""

import pandas as pd
import numpy as np
import math



#direct = '/content/players.csv' #путь к файлу с полученным датафреймом
direct = r'C:\Mary\players.csv' #дома

players = pd.read_csv(direct, names = ['player_id', 'PFR',	'VPIP',	'o_Limp',	'3bet', 'VPIP/PFR']) # считываю данные в датафрейм
players.head()

players.describe()

players.info()

clastering = players.groupby('player_id').mean().reset_index() #сгруппированный по игрокам датасет с вычислением средних значений

clastering.info() # общая информация по сгруппированному датасету

clastering['VPIP/PFR'] = (clastering['VPIP'] / clastering['PFR']) #вычисляю значения дополнительного параметры

clastering.loc[ clastering['VPIP/PFR'].isna() ] #остались строки с NAN там где PFR и VPIP были 0

clastering.loc[ clastering['VPIP/PFR'] == np.inf ] #остались строки с NAN там где PFR был 0

clastering.loc[ clastering['VPIP/PFR'].isna(), 'VPIP/PFR' ] = -1 #присваиваю значениям c NaN метку -1

clastering.loc[ clastering['VPIP/PFR'].isna() ] #теперь нет строк с NaN

clastering.loc[ clastering['VPIP/PFR'] == np.inf, 'VPIP/PFR' ] = -2 #присваиваю значениям c inf метку -2

clastering.loc[ clastering['VPIP/PFR'] == np.inf ] #и нет строк с бесконечностью

clastering['VPIP/PFR'].value_counts()

"""Добавлю новые параметры, см.самый конец файла насчет выбора параметров
VPIP/PFR**2, PFR*o_Limp
"""
clastering['VPIP/PFR**2'] = (clastering['VPIP/PFR'])**2 #вычисляю значения дополнительного параметры
#clastering['expVPIP/PFR'] = np.exp(clastering['VPIP/PFR']) #получилась какая-то ерунда
#clastering['PFR*o_Limp'] = (clastering['PFR'] * clastering['o_Limp']) #вычисляю значения дополнительного параметры
#clastering['PFR**4'] = (clastering['PFR'])**4
# clastering['o_Limp**4'] = (clastering['o_Limp'])**4 #еще квадрат пробовала и экспоненту, метрика ниже
clastering.head(5)

#записала в файл что получилось
clastering.to_csv(r'C:\Mary\clastering.csv', index = False, header = True)

"""**Подготовка к кластеризации**    
Признаки - 'PFR',	'VPIP',	'o_Limp',	'3bet', 'VPIP/PFR'
"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler
from matplotlib import colors
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.cluster import DBSCAN, AgglomerativeClustering



#X = clastering[['PFR',	'VPIP',	'o_Limp',	'3bet', 'VPIP/PFR', 'VPIP/PFR**2', 'PFR*o_Limp']].copy() #признаки
X = clastering[['PFR',	'VPIP',	'o_Limp',	'3bet', 'VPIP/PFR', 'VPIP/PFR**2']].copy() #признаки
#y = clastering['player_id'].copy() #не участвует в кластеризацции

X.describe()

"""Признаки в разных пределах,т.к. все модели кластеризации работают с расстояниями, то
смасштабирую все признаки чтобы они были в одних пределах
НЕ МАСШТАБИРОВАЛА, СМ,НИЖЕ
"""

#Сейчас все параметры имеют среднее 0 и стандартное отклонение 1
#scaler = StandardScaler()
#X_scaled = scaler.fit_transform(X)
#X_scaled.mean(axis = 0), X_scaled.std(axis = 0)
#Метркиа и визуально после масштабирования сталогораздо хуже. В среднем метрика силуэт около 0,3 -0,53
# не буду делать масштабирование

#проверка оптимального количества кластеров методом локтя
k_inertia = [] #создаю список для сумм квадратов внутрикластерных расстояний, рассчитываем для каждого кол-ва кластеров
ks = range(1,10) #задаю диапазон кластеров
for k in ks:
  clf_kmeans = KMeans(n_clusters = k)
  clusters_kmeans = clf_kmeans.fit_predict(X)
  k_inertia.append(clf_kmeans.inertia_)

plt.plot(ks, k_inertia)
plt.plot(ks, k_inertia, 'g^')
plt.title('График локтя для метода KMeans')
plt.xlabel('Кол-во кластеров')
plt.ylabel('Сумма квадратов внутрикластерных расстояний')
plt.show()

"""Судя по графику совсем переломными точками являются 3 и 5. Дальше проверю еще

Уменьшение количества признаков до 2-х для возможности визуализации
"""

from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.model_selection import train_test_split
from sklearn.metrics import silhouette_score



pca = PCA(n_components = 2) #Инициализирую модель метода главных компонент
X_pca = pca.fit_transform(X) #обучаю на параметрах

X_pca.shape

X_pca.shape

tsne = TSNE(random_state = 42, perplexity = 25) #модель TSNE уменьшение размерности
X_tsne = tsne.fit_transform(X)
X_tsne.shape

"""**Кластеризация при помощи алгоритма KMeans**"""

kmeans = KMeans(n_clusters = 2) #создаем объект кластеризации c 5-ю кластерами
clusters = kmeans.fit_predict(X) #обучаем модель на данных, каждой точке присваивается свой кластер
clastering.insert(6, 'cluster_2', clusters, False) #записываю в исходный датафрейм
clastering.head()

kmeans = KMeans(n_clusters = 4) #создаем объект кластеризации c 4-мя кластерами
clusters = kmeans.fit_predict(X) #обучаем модель на данных, каждой точке присваивается свой кластер
clastering.insert(7, 'cluster_4', clusters, False) #записываю в исходный датафрейм
clastering.head()

kmeans = KMeans(n_clusters = 3) #создаем объект кластеризации c 3-мя кластерами
clusters = kmeans.fit_predict(X) #обучаем модель на данных, каждой точке присваивается свой кластер
clastering.insert(8, 'cluster_3', clusters, False) #записываю в исходный датафрейм
clastering.head()

sil_K_3 = silhouette_score(X, clastering.cluster_3) # метрика качества кластеризации для 3-х кластеров
print(f'silhoette KMeans 3 кластера - {round(sil_K_3, 3)}')

sil_K_4 = silhouette_score(X, clastering.cluster_4) # метрика качества кластеризации для 4-х кластеров
print(f'silhoette KMeans 4 кластера - {round(sil_K_4, 3)}')

sil_K_2 = silhouette_score(X, clastering.cluster_2) # метрика качества кластеризации для 5-ти кластеров
print(f'silhoette KMeans 2 кластеров - {round(sil_K_2, 3)}')

plt.figure(figsize = (12,5))
plt.subplots_adjust(hspace = 0.5) #задаю расстояние между рисунками
plt.suptitle('Уменьшение размерности PCA, Кластеризация KMeans')

plt.subplot(1,3,1)
plt.scatter(x = X_pca[:, 0], y = X_pca[:, 1], c = clastering.cluster_2)
plt.title('2 кластеров')

plt.subplot(1,3,2)
plt.scatter(x = X_pca[:, 0], y = X_pca[:, 1], c = clastering.cluster_3)
plt.title('3 кластера')

plt.subplot(1,3,3)
plt.scatter(x = X_pca[:, 0], y = X_pca[:, 1], c = clastering.cluster_4)
plt.title('4 кластера')

plt.show()

plt.figure(figsize = (12,5))
plt.subplots_adjust(hspace = 0.5) #задаю расстояние между рисунками
plt.suptitle('Уменьшение размерности TSNE, Кластеризация KMeans')

plt.subplot(1,3,1)
plt.scatter(x = X_tsne[:, 0], y = X_tsne[:, 1], c = clastering.cluster_2)
plt.title('2 кластеров')

plt.subplot(1,3,2)
plt.scatter(x = X_tsne[:, 0], y = X_tsne[:, 1], c = clastering.cluster_3)
plt.title('3 кластера')

plt.subplot(1,3,3)
plt.scatter(x = X_tsne[:, 0], y = X_tsne[:, 1], c = clastering.cluster_4)
plt.title('4 кластера')

plt.show()

"""АГЛОМЕРАТИВНАЯ КЛАСТЕРИЗАЦИЯ"""

for k in [3,4,2]: #перебираю число кластеров от 3 до 5
    agg = AgglomerativeClustering(n_clusters=k, linkage='ward')

    clusters = agg.fit_predict(X) #обучаем модель на данных, каждой точке присваивается свой кластер

    clastering.insert(9, f'Agg_clust_{k}', clusters, False) #записываю в исходный датафрейм

clastering.head()

sil_A_3 = silhouette_score(X, clastering.Agg_clust_3) # метрика качества кластеризации для 3-х кластеров
print(f'silhoette AgglomerativeClustering 3 кластера - {round(sil_A_3, 3)}')

sil_A_4 = silhouette_score(X, clastering.Agg_clust_4) # метрика качества кластеризации для 4-х кластеров
print(f'silhoette AgglomerativeClustering 4 кластера - {round(sil_A_4, 3)}')

sil_A_2 = silhouette_score(X, clastering.Agg_clust_2) # метрика качества кластеризации для 5-ти кластеров
print(f'silhoette AgglomerativeClustering 2 кластеров - {round(sil_A_2, 3)}')

plt.figure(figsize = (12,5))
plt.subplots_adjust(hspace = 0.5) #задаю расстояние между рисунками
plt.suptitle('Уменьшение размерности PCA, AgglomerativeClustering')

plt.subplot(1,3,1)
plt.scatter(x = X_pca[:, 0], y = X_pca[:, 1], c = clastering.Agg_clust_2)
plt.title('2 кластеров')

plt.subplot(1,3,2)
plt.scatter(x = X_pca[:, 0], y = X_pca[:, 1], c = clastering.Agg_clust_3)
plt.title('3 кластера')

plt.subplot(1,3,3)
plt.scatter(x = X_pca[:, 0], y = X_pca[:, 1], c = clastering.Agg_clust_4)
plt.title('4 кластера')

plt.show()

plt.figure(figsize = (12,5))
plt.subplots_adjust(hspace = 0.5) #задаю расстояние между рисунками
plt.suptitle('Уменьшение размерности TSNE, AgglomerativeClustering')

plt.subplot(1,3,1)
plt.scatter(x = X_tsne[:, 0], y = X_tsne[:, 1], c = clastering.Agg_clust_2)
plt.title('2 кластеров')

plt.subplot(1,3,2)
plt.scatter(x = X_tsne[:, 0], y = X_tsne[:, 1], c = clastering.Agg_clust_3)
plt.title('3 кластера')

plt.subplot(1,3,3)
plt.scatter(x = X_tsne[:, 0], y = X_tsne[:, 1], c = clastering.Agg_clust_4)
plt.title('4 кластера')

plt.show()

"""Кластеризация DBSCAN"""

dbscan = DBSCAN(eps = 0.01, min_samples = 10)

clusters = dbscan.fit_predict(X) #обучаем модель на данных, каждой точке присваивается свой кластер

clastering.insert(12, 'DBSCAN', clusters, False) #записываю в исходный датафрейм

clastering.head()

sil_D_3 = silhouette_score(X, clastering.DBSCAN) # метрика качества кластеризации для 3-х кластеров
print(f'silhoette DBSCAN {len(np.unique(dbscan.labels_))} кластера - {round(sil_D_3, 3)}')

#кол-во кластеров. -1 - выь
np.unique(dbscan.labels_)

#узн
len(dbscan.labels_[ dbscan.labels_ == -1])

clastering = clastering.drop('DBSCAN', axis = 1)

plt.figure(figsize = (7,5))

plt.scatter(x = X_pca[:, 0], y = X_pca[:, 1], c = clastering.DBSCAN)
plt.title('Уменьшение размерности PCA, DBSCAN')
plt.show()

plt.figure(figsize = (7,5))

plt.scatter(x = X_tsne[:, 0], y = X_tsne[:, 1], c = clastering.DBSCAN)
plt.title('Уменьшение размерности TSNE, DBSCAN')
plt.show()

"""Посчитаю корреляцию между предсказанными кластерами и признаками. Потом добавлю новые признаки, сделанные из тех, у которых корр больше
Кластеризацию возьмп по аггломерации 3 кластера, т.к. там самая большая метрика
"""

sns.heatmap(clastering[['PFR', 'VPIP', 'o_Limp', '3bet', 'VPIP/PFR', 'Agg_clust_3']].corr(), annot = True)
plt.title('Матрица корреляции Пирсона Аггломерация 3 кластера')
plt.show()

sns.heatmap(clastering[['PFR', 'VPIP', 'o_Limp', '3bet', 'VPIP/PFR', 'Agg_clust_4']].corr(), annot = True)
plt.title('Матрица корреляции Пирсона Аггломерация 4 кластера')
plt.show()

"""Самая высокая по модулю корреляция PFR, o_Limp, VPIP/PFR
Селаю доп.параметры:
VPIP/PFR**2
PFR*o_Limp
и посмотрю что будет с метриками
"""

clust = clastering[['PFR', 'VPIP', 'o_Limp', '3bet', 'VPIP/PFR', 'cluster']].groupby('cluster').agg(['min', 'mean', 'max']).round(2)
clust