#### <ins>Создание адверсариальной атаки на классификатор MNIST — генерация шума, меняющего предсказание модели</ins>. 
Задание: Обучить шум, который при добавлении к оригинальной картинке, заставит модель LeNet, обученную на распознание цифр датасета MNIST, ошибаться в пользу другого класса.

Основные этапы (на всех этапах применялся (PyTorch):
- выполнено обучение модели LeNet с применением готовых модулей, находящихся в открытом доступе,
- параметры обученной модели с лучшей метрикой сохранены в файл "mnist_0.985.pth", чтобы не нужно было каждый раз обучать модель заново,
- реализован итеративный процесс обучения параметров шума с применением метода градиентного подъема (аниградиент).

Скрипт выполнения задания в формате .py в [файле](Adv_noise_MNIST/13_9_cv3_hw.py).  
Выполненное задание с полученными результатами в формате .ipynb в [файле](Adv_noise_MNIST/13_9_CV3_HW.ipynb).  
Вспомогательные файлы расположены в [папке](Adv_noise_MNIST), комментарии по их применению даны в основном файле с заданием.

