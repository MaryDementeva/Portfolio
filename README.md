<img src="фото для резюме.jpg" align="left" width="110" height="120" />

**Дементьева Мария Александровна**<br/>

email: mbrovarova@mail.ru<br/>
тел:+7 905 305 8017

<br/>
<br/>
В настоящее время заканчиваю обучение на курсе <ins>Data Scientist: расширенная траектория</ins> в образовательной онлайн-платформе Нетология. <br/>  

[Ссылка на программу курса](https://netology.ru/programs/prodatascience?programName=data-scientist#/modul_2)

### Машинное обучение<br/>
#### <ins>Нейросетевой перенос стиля (Style Transfer)</ins>.
Задание: Разработать алгоритм переноса художественного стиля между изображениями.

Основные этапы (на всех этапах применялся (PyTorch):
- выполнена предобработка изображений в соответствии с требованими модели,
- заданы фукции потерь content loss и style loss и матрица Грама,
- сформирована модель переноса стиля на базе предобученной сети Vgg 19,
- задана функция переноса стиля,
- выполнен перенос стиля с разных изображения стиля на одно и тоже исходное изображение.
  
Выполненное задание в [файле](training_projects/Style_transfer/TransferLearn.ipynb).
Использованные изображения расположены в [папке](training_projects/Style_transfer).

#### <ins>Создание адверсариальной атаки на классификатор MNIST — генерация шума, меняющего предсказание модели</ins>. 
Основные этапы (на всех этапах применялся (PyTorch):
- выполнено обучение модели LeNet с применением готовых модулей, находящихся в открытом доступе,
- параметры обученной модели с лучшей метрикой сохранены в файл "mnist_0.985.pth", чтобы не нужно было каждый раз обучать модель заново,
- hеализован итеративный процесс обучения параметров шума с применением метода градиентного подъема (аниградиент).

Выполненное задание в [файле](training_projects/Adv_noise/13_9_CV3_HW.ipynb).
Вспомогательные файлы расположены в [папке](training_projects/Adv_noise), пояснения по их применению даны в основном файле с заданием.

#### <ins>Обучение модели U-Net для решения задачи семантической сегментации</ins>. 
Задание: Построить и обучить модель U-Net для семантической сегментации сгенерированных окружностей. 

Основные этапы:
- создан отдельный класс для формирования датасета для обучения модели,
- построена и обучена модель U-Net (PyTorch),
- выполнена визуализация исходных объектов и предсказанных масок

Выполненное задание в [файле](training_projects/U_Net_segmentation/13_1_CV2_segm.ipynb).
Вспомогательный файл расположен в [папке](training_projects/U_Net_segmentation), пояснения по его применению даны в основном файле.

#### <ins>Реализация задачи детекции клеток крови на основе сети SSD</ins>.
Задание: Реализовать задачу детекции клеток крови на основе сети SSD (датасет BCCD).
Использовался Python.

Основные этапы:
- создан отдельный класс для формирования датасета BCCD для передачи его в модель,
- обучена модель SSD (PyTorch),
- отображены предсказанные и истинные координаты и типы клеток крови.

Выполненное задание в [файле](training_projects/BCCD/13_1_CV1_detect.ipynb).
Вспомогательные файлы расположены в [папке](training_projects/BCCD), пояснения по их применению даны в основном файле с заданием.

#### <ins>Построение классификатора изображений на основе предобученной нейронной сети</ins>.  
По заданию требовалось построить бинарнай классификатор изображений. При этом значение функции потерь должно быть не более 0,3.<br/>
Использовался Python.  
Основные этапы:   
- загрузка изображений (glob), разделение на обучающую и тестовую выборки, 
- загрузка предобученной модели vgg16 без полносвязных слоев (tensorflow.keras), 
- последовательный подбор полносвязных слоев для достижения требуемого значения функции потерь (tensorflow.keras).

Выполненное задание в [файле](test_projects/HW_dogs_vs_cats.ipynb). 

#### <ins>Кластеризация игроков в покер в зависимости от их поведения во время игры с целью определения наилучшей стратегии</ins>.  
Использовался Python.  
Действия игроков записаны в текстовых файлах в определенном формате.   
Разбор действий выполнялся по определенным правилам, не обозначенным в файле по просьбе заказчика. Анализ полученных результатов также не показан в файле по просьбе заказчика.  

Основные этапы:   
- считывание и разбор по правилам данных из текстовых файлов (glob, re), 
- работа с датафреймами (pandas), 
- формирование новых параметров для улучшения метрик кластеризации, 
- кластеризация игроков несколькими методами для выбора оптимального (sklearn),
- расчет метрик, понижение размерности для визуализации полученной разбивки (sklearn, sns, matplotlib).

Выборка данных из текстовых файлов и их компоновка в датафрейм выполняется в [файле](poker/poker.ipynb).  
Кластеризация выполняется в [файле](poker/poker_clster.ipynb).

#### <ins>Автоматический разбор присланных за день штрафов, с сортировкой по правилам и рассылкой на почту</ins>.   
Использовался Python.
Основные этапы: 
- выборка файлов по дате создания (sys, os, glob, datetime);
- чтение pdf файлов и выбор из них данных (данные на автомобиль, сумма штрафа, фото номера) (PyPDF2, re);
- запись выбранных данных в эксель файл (openpyxl);
- отправка на почту (smtplib, email.message).

Разбор файлов, формирование отчетов и отправка отчета на почту в [файле](drivers/drivers.ipynb). 

### Анализ данных<br/>
#### <ins>Выбор метода для оценки различий между группами: обработка результатов A/B тестов</ins>.  
Использовался Python.  
Основные этапы:   
- анализ данных, построение графиков, расчет статистических параметров (scipy), 
- подбор критерия в зависимости от типа распределения (scipy), 
- интерпритация результатов.
  
Выполненное задание в [файле](test_projects/АВ_test.ipynb).

#### <ins>АВ тестирование</ins>
Выполнено А/В тестирование гипотез для разных наборов данных с определением наиболее подходящего критерия проверки.
Использованные библиотеки: numpy, scipy.stats, matplotlib.pyplot, seaborn.  

Выполненное задание в [файле](training_projects/HW_AB.ipynb).

#### <ins>Проверка гипотез</ins>
В задании выполнена проверка нескольких гипотез, выбраны походящие критерии проверки в зависимости от конкретной задачи.
В ходе выполнения задания использовались библиотеки:numpy, scipy.stats, pandas, seaborn, matplotlib.pyplot.  

Выполненное задание в [файле](training_projects/ДЗ_Проверка_гипотез.ipynb).

#### <ins>Анализ данных, поиск выбросов и обработка экстремальных значений</ins>
Решение здачи классификации типа стекла в зависимости от его химического состава.   
Проведен предварительный анализ данных, определены и обработаны выбросы различными методами, выполнена классификация типов стекол и посчитаны метрики. Выполнено сравнение полученных метрик и анализ наиболее подходящего метода для обработки выбросов. 
В ходе выполнения задания спользовались библиотеки: pandas, sklearn, sklearn.RandomForestClassifier, sklearn.IsolationForest.  

Выполненное задание в [файле](training_projects/ДЗ_8_10_выбросы.ipynb).

### SQL
#### <ins>Тестовое задание на написание SQL запросов</ins>.
Использовались cte, оконная функция.         
Задание: На основе данных о постах на странице ВКонтакте определить какие факторы больше всего влияют на количество лайков: время суток публикации, день недели или промежуток между постами.
Основные этапы:
- собраны данные о количестве постов, дате и времени поста и лайков к ним;
- создана база данных PostgreSQL;
- написаны запросы, на основании полученных данных сделаны выводы.

Выполненное задание в [файле](SQL/VK_likes_gen.sql).

#### <ins>Получение данных при помощи SQL запросов</ins>
Для получения данных использовались JOIN, оконные функции, cte, подзапросы.

Выполненное задание в [файле](SQL/SQL_result.sql).
