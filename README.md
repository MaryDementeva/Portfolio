#### <ins>Создание адверсариальной атаки на классификатор MNIST — генерация шума, меняющего предсказание модели</ins>. 
Задание: Обучить шум, который при добавлении к оригинальной картинке, заставит модель LeNet, обученную на распознание цифр датасета MNIST, ошибаться в рользу другого класса.

Основные этапы (на всех этапах применялся (PyTorch):
- выполнено обучение модели LeNet с применением готовых модулей, находящихся в открытом доступе,
- параметры обученной модели с лучшей метрикой сохранены в файл "mnist_0.985.pth", чтобы не нужно было каждый раз обучать модель заново,
- реализован итеративный процесс обучения параметров шума с применением метода градиентного подъема (аниградиент).

Скрипт выполениня задания в формате .py в [файле](training_projects/Adv_noise/13_9_CV3_HW.ipynb).
Выполненное задание с полученными результатами в формате .ipynb в [файле](training_projects/Adv_noise/13_9_CV3_HW.ipynb).
Вспомогательные файлы расположены в [папке](training_projects/Adv_noise), комментарии по их применению даны в основном файле с заданием.

