# -*- coding: utf-8 -*-
"""TransferLearn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YEIGbk68081WRsSE0r3A7EPdy68VjYdx
"""
print('ИМПОРТИРУЕМ БИБЛИОТЕКИ')

import torch
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
from PIL import Image
import torchvision.transforms as transforms
import torchvision.models as models
import torch.nn.functional as F
from copy import deepcopy
#import cv2
import os
import warnings

warnings.filterwarnings('ignore')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

"""#Загружаем и предобрабатываем изображения"""

print('ЗАГРУЗКА И ОБРАБОТКА ИЗОБРАЖЕНИЙ')

imsize = 256 #if torch.cuda.is_available() else 128 #если cuda недоступна, то меньший размер изображения

inp_transform = transforms.Compose([
    transforms.Resize((imsize, imsize)), #меняем размер изображения в зависимости от наличия/отсутствия cuda
    transforms.ToTensor()]) #переводим в тензор, масштабируем

def image_loader(img):
  """функция загрузки и преобразования исходного изображения.
  Меняем размер изображения а зависимости от доступности cuda,
  масштабируем и переводим в тензор,
  добавляем размерность батча (=1) по требовааниям входных данных модели
  """
  image = Image.open(img)
  image = inp_transform(image).unsqueeze(0) #добавляем размерность батча
  #переносим на device, переводим в float32, т.к в torch по умолчаеию тип данных float32
  return image.to(device, torch.float32)

#Загрузка изображения содержания
if os.path.exists('/In_Out/Content.jpg'): #если в volume есть входящее изображение
  content_img = image_loader('/In_Out/Content.jpg') #то загружаем входящее изображение от пользователя
else: #если нет, то используем изображение по умолячанию
  content_img = image_loader('default_imgs/Content.jpg')

#Загрузка изображения стиля
if os.path.exists('/In_Out/Style.jpg'): #если в volume есть входящее изображение
  style_img = image_loader('/In_Out/Style.jpg') #то загружаем входящее изображение от пользователя
else: #если нет, то используем изображение по умолячанию
  style_img = image_loader('default_imgs/Style.jpg')

"""#Задаем функции потерь и матрицу Грама"""

class ContentLoss(nn.Module):
  def __init__(self, target):
    super().__init__()
    self.target = target.detach() #отсоединяем исходное изображение от графа вычислений чтобы не менять его

  def forward(self, input):
    #вычисляем ф-цию потерь- сравниваем изображение на входе с исходным изображением
    self.loss = F.mse_loss(input, self.target)
    return input

def gram_matrix(input):
  b,c,h,w = input.size() #b - кол-во батчей (=1), c - кол-во каналов, h*w - ширина *высота изобр
  #меняем размер входящего тензора.
  #Кол-во строк = кол-ву каналов; в каждой строке вытянутые в вектор значения каждого канала
  features = input.view(b*c, h*w)
  #print(features.size())
  gram = torch.mm(features, features.t()) #формируем матрицу Грама
  #нормализуем значения матрицы Грама
  return gram.div(b*c*h*w)

class StyleLoss(nn.Module):
  def __init__(self, target_feature):
    super().__init__()
    self.target = gram_matrix(target_feature).detach()

  def forward(self, input):
    gram = gram_matrix(input)
    self.loss = F.mse_loss(gram, self.target) #считаем ф-цию потерь между матр.Грама входного и исходного изображений
    return input

"""#Создаем модель transfer learning"""

print('ИНИЦИАЛИЗИРУЕМ МОДЕЛЬ')

#за основу берем предобученную сеть vgg19, переволим в режиим предсказания чтобы не менять веса
#модель уже скачана и лежит в папке образа "model_vgg19"

# Путь к весам скачанной модели внутри образа
model_weights_path = "model_vgg19/vgg19-dcbb9e9d.pth"

#cnn = models.vgg19(pretrained = True).features.to(device).eval()
# Создаём модель без предобученных весов
model = models.vgg19(pretrained=False)

# Загружаем веса из файла
state_dict = torch.load(model_weights_path, map_location=device)

# Загружаем state_dict в модель
model.load_state_dict(state_dict)

# Берём только 'features', переносим на устройство и переводим в режиим предсказания чтобы не менять веса
cnn = model.features.to(device).eval()


#создаем список слоев, после которых будем считать ф-ции потерь и матрицы Грама
content_layers = ['conv_1'] #для исходного изображения только 1-й сверточный слой

#для извлечения паттернов стиля используем сверточные слои:
style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5', 'conv_6', 'conv_7',
                'conv_8', 'conv_9','conv_10', 'conv_11', 'conv_12', 'conv_13','conv_14',
                'conv_15', 'conv_16', 'conv_17','conv_18', 'conv_19', 'conv_20']


def create_model_losses(
    cnn,
    style_img, content_img,
    content_layers = content_layers,
    style_layers = style_layers):
  #Ф-ция создания модели переноса стиля из нужных слоев
  #и подсчета ф-ций потерь

  cnn = deepcopy(cnn) #создаем копию исходной сети чтобы не портить исходную и выбирать из нее нужные слои

  #создаем пустые списки потерь содержания и стиля
  content_losses = []
  style_losses = []

  model = nn.Sequential() #создаем пустую модель, в которую потом будем сохранять нужные слои
  i = 0 #задаем счетчик сверточных слоев
  #проходим по слоям и добавляем номера в названия для удобства дальнейшего использования
  #затем добавояем в model
  for layer in cnn.children():
    if isinstance(layer, nn.Conv2d):
      i+=1
      name = 'conv_{}'.format(i)
    elif isinstance(layer, nn.ReLU):
      name = 'relu_{}'.format(i)
      layer = nn.ReLU(inplace=False)
    elif isinstance(layer, nn.MaxPool2d):
      name = 'pool_{}'.format(i)
    elif isinstance(layer, nn.BatchNorm2d):
      name = 'bn_{}'.format(i)
    else:
      raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))

    model.add_module(name, layer)

    if name in content_layers:
      #если слой входит в список слове, для которых считаем content loss
      target = model(content_img).detach()  #пропускаем исходное изображение через слой
      cont_loss = ContentLoss(target) #считаем отклонение от исходного изображения
      model.add_module("conten_loss_{}".format(i), cont_loss)
      content_losses.append(cont_loss)

    if name in style_layers:
      #если слой входит в список слоев, для которых считаем style_loss
      target_feature = model(style_img).detach()
      stl_loss = StyleLoss(target_feature)
      model.add_module("style_loss_{}".format(i), stl_loss)
      style_losses.append(stl_loss)

  for i in range(len(model) - 1, -1, -1):
    if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):
      break

  model = model[:(i+1)] #убираем слои после contentloss или style loss

  return model, style_losses, content_losses

input_img = content_img.clone() #копируем изображение, чтобы не портить исходное

def inp_optimizer(input_img):
  #указываем, что для этого изображения нужно считать и сохранять градиенты
  optimizer = optim.LBFGS([input_img.requires_grad_()])
  return optimizer

def run_style_transfer(
    cnn,
    content_img, style_img,
    input_img,
    num_steps = 300,
    style_weight = 10000000, content_weight = 1):
  print('Формируем модель переноса стиля')

  model, style_losses, content_losses = create_model_losses(cnn, style_img, content_img)
  optimizer = inp_optimizer(input_img)

  print('Формируем выходное изображение')
  run = [0] #задаем счетчик
  while run[0] < num_steps:
    def closure():
      input_img.data.clamp_(0, 1) #обрезаем значения <0 <1 входного изображения (inplace)
      optimizer.zero_grad() #обнуляем грандиенты чтобы не накопить лишнего
      model(input_img) #вычисляем loss ф-ции модели
      style_score = 0
      content_score = 0

      for sl in style_losses:
        style_score += sl.loss #суммируем полученные loss
      for cl in content_losses:
        content_score += cl.loss

      style_score *= style_weight #умножаем на веса
      content_score *= content_weight

      loss = style_score + content_score #вычисляем общую loss
      loss.backward() #вычисляем градиенты

      run[0] += 1
      if run[0] % 50 == 0:
        print("run {}:".format(run))
        print('Style Loss : {:4f} Content Loss: {:4f}'.format(
                    style_score.item(), content_score.item()))
        print()

      return style_score + content_score

    optimizer.step(closure)
    input_img.data.clamp_(0,1) #еще раз обрезаем значения, вышедшие за пределы 0,1

    return input_img

"""#Запуск функции переноса стиля"""

print('ЗАПУЩЕН АЛГОРИТМ ПЕРЕНОСА СТИЛЯ, ЭТО ЗАЙМЕТ НЕКОТОРОЕ ВРЕМЯ')

output = run_style_transfer(cnn,
                            content_img, style_img,
                            input_img,
                            style_weight=10000000000, content_weight=0.00001)

output = torch.squeeze(output, dim = 0) #удаляем размерность батча
output = output.permute(1,2,0) #переносим кол-во каналов на последнее место
output = output.detach().cpu().numpy() #отключаем градиенты, переводим в numpy
output = output*255 #переводим в размерность изображения (было 0-1, стало 0-255)
output = output.astype(np.uint8) #переводим в формат изображения

out_img = Image.fromarray(output) #преобразуем в изображение

out_img.save('/In_Out/out_img.jpg', format = 'JPEG') #сохраняем в файл

print('ИЗОБРАЖЕНИЕ СОХРАНЕНО В ФАЙЛ "out_img.jpg"')