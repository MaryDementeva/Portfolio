# -*- coding: utf-8 -*-
"""13_1_CV1_detect.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14JZzsaefzR6bgK3BXZHaibT473TRfnyZ

**Копирование и скачивание датасета BCCD**
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# 
# git clone https://github.com/Shenggan/BCCD_Dataset.git
# cd BCCD_Dataset
# 
# cp export.py ../
# cp plot.py ../

"""Для корректной работы в скачанном export.py нужно поменять путь к папке, в которой хранятся аннотации на
BCCD_Dataset/BCCD/Annotations/*.xml
"""

#выполнить файл для формирования test.csv с данными картинок датасета
#этим файлом надо заменить файл, который идет с датасетом
#можно сразу загрузить ранее сформированный файл test.csv, тогда эту строку не запускать
!python /content/export.py

import os
import numpy as np
import torch
import torch.utils.data
from PIL import Image, ImageDraw
import pandas as pd
import torchvision as tv

import time
from torchvision.models.detection import ssd300_vgg16
import matplotlib.pyplot as plt

device = 'cuda' if torch.cuda.is_available() else 'cpu' #колаб не всегда позволят подключиться к cuda
device

class BCCD(torch.utils.data.Dataset):
  """класс формирования датасета BCCD
  """
  def __init__(self, root = '/content/', trans = None):
    """trans - преобразования, которые можно потом делать с train данными
    root - путь для колаб
    """
    self.root = root

    self.data = pd.read_csv(os.path.join(root, 'test.csv')) #считываем данные из файла в датафрейм пандас

    #записываю в атрибут imgs пути к картинкам, unique чтобы точно не было дублей
    self.imgs = self.data['filename'].unique()
    #обязательные преобразования входных картинок для приведения к требованиям сети
    #модель принимает на вход картинку 300х300 со значениями от 0 до 1.
    #но эти преобразования она входящего изображения она делает внутри себя, поэтому здесь они закомментированы
    self.transforms = tv.transforms.Compose([
        #tv.transforms.Resize([300,300]),
        tv.transforms.ToTensor(),
        #tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    #выбираю уникальные классы из столбца cell_type + класс фона
    self.classes = ['background'] + list(self.data['cell_type'].unique())
    #записываю словарь соответствия классов и номеров классов в атрибут
    self.classes_idx = {c : i for i, c in enumerate(self.classes)}

  def get_image(self, idx):
    """метод получения изображения по индексу
    """
    filename = self.imgs[idx]
    img = Image.open(os.path.join(self.root+'BCCD_Dataset/BCCD/JPEGImages',filename)).convert("RGB")
    return img


  def __getitem__(self, idx):
    """магческий метод для возможности обращения к объекту класса как к итерируемому множеству - по индексу
    """
    filename = self.imgs[idx]

    #открываем изображение как изображение из файла по пути, для дальнейшей обработки
    img = Image.open(os.path.join(self.root+'BCCD_Dataset/BCCD/JPEGImages',filename)).convert("RGB")

    x = self.data
    x = x[x['filename'] == filename ] #выбираем нужный файл (в нем несколько объектов)
    x = x[x.xmin < x.xmax] #проверяем чтобы xmin < xmax и ymin < ymax
    x = x[x.ymin < x.ymax] #есть 2 записи, в которых они равны, т.е. рамка - точка
    x = np.array(x)

    for i in range (len(x)): #для каждого объекта в файле
      x[i,1] = self.classes_idx[x[i,1]] #присваиваем номер класса вместо названия

    #выбираем все метки классов (1-й индекс (0-й - пути к файлам))
    labels = torch.as_tensor(x[:,1].astype(int), dtype = torch.int64).to(device)
    #выбираем координаты углов
    boxes = torch.as_tensor(x[:, [2,4,3,5]].astype(float), dtype = torch.float32).to(device)

    image_id = torch.tensor([idx])
    area = (boxes[:,2] - boxes[:,0]) * (boxes[:,3] - boxes[:, 1])  #0-xmin, 1-ymin, 2-xmax, 3-ymax

    iscrowd = torch.zeros((len(x),), dtype=torch.int64)

    img = self.transforms(img).to(device) #применяем обязательные преобразования к изображению

    return img, {'boxes': boxes, 'labels': labels}

  def __len__(self):
      return len(self.imgs) #возвращает общее число файлов(картинок)

BCCD_data = BCCD() #создаем объект класса

BCCD_data.classes_idx #посмотреть как работает

BCCD_data.get_image(9)

BCCD_data[9]



"""**Задание модели**"""

model = ssd300_vgg16(pretrained = True).to(device)

"""**Обучение**"""

len(BCCD_data) #всего картинок

len_test=5 #приму длину тестовой выборки - 5 чтобы потом проще было отрисовывать результат предсказания модели

torch.manual_seed(42)
index = torch.randperm(len(BCCD_data)).tolist() #в случайном порядке переставляем индексы в пределах от 0 до всего кол-ва картинок

trn = list(index[:-len_test]) #список индексов train, все, кроме 5 последних элементов
tst = list(index[-len_test:]) #список индексов test, 5 последних элемента

epochs = 50 #количество эпох

batch_size = 50 #размер батча

model.train() #переходим в режим обучения модели

trainer = torch.optim.Adam(model.parameters(), lr = 0.0001) #задаем оптимизатор и шаг обучения
start = time.time() #фиксирем время начала обучения

for ep in range(epochs): #счетчик эпох
  perm = np.random.permutation(trn) #в случайном порядке перемешиваем train датасет в каждой эпохе
  i = 0 #счетчик количества обработанных картинок
  #инициализируем начальное (нулевое) состояние функции потерь
  l0 = 0
  l1 = 0
  l2 = 0
  ln = 0  #заводим счетчик обработанных батчей

  while True:
    features = []
    targets = []
    trainer.zero_grad() #обнуляем градиенты чтобы не приплюсовать что-нибудь лишнее
    for j in range(batch_size): #из всех объектов в батче формируем наор картинок и целевых переменных (рамки, классы)
        if i >= len(perm):
          break
        p, t = BCCD_data[perm[i]]
        features.append(p) #изображение
        targets.append(t) #рамки и класс
        i+=1
    pred = model(features, targets) #передаем выбранные наборы в модель, получаем предсказанные значения
    loss = pred['bbox_regression'] * pred['bbox_regression'] * 20 + pred['classification']
    loss.backward() #просчитываем грандиенты
    trainer.step() #делаем шаг оптимизатора
    #считаем ф-цю потерь регрессии (предсказание координат рамок)
    l1 += pred['bbox_regression'].item()
    # считаем ф-цию потерь классификации
    l2 += pred['classification'].item()
    # считаем суммарную функцию потерь
    l0 += loss.item()
    ln+=1 # увеличиваем счетчик кол-ва обработанных батчей

    if i >= len(perm):
      break

  print(f'time - {round((time.time() - start)/60000,5)}мин, epoch - {ep}, l0/ln - {round(l0/ln,4)}, l1/ln - {round(l1/ln,4)},l2/ln - {round(l2/ln,4)}')
  start = time.time()

"""Использованные опитизаторы:   
epoch - 19, l0/ln - 1.0175, l1/ln - 0.0902,l2/ln - 0.8546 - Адам   20 эпох   
epoch - 19, l0/ln - 3.6808, l1/ln - 0.3233,l2/ln - 1.5824 Adamax   20 эпох   
epoch - 19, l0/ln - 3.4806, l1/ln - 0.3089,l2/ln - 1.5695   SGD    20 эпох  
epoch - 49, l0/ln - 0.0873, l1/ln - 0.0242,l2/ln - 0.0754 Адам 50 эпох - итоговое предсказание ниже на этой модели
"""

BCCD_data[176][1]['boxes'][1]

model.eval()
#tst = list(range(len(BCCD_test)))
for i in tst:
  p,t = BCCD_data[i]
  outputs = model([p])
  img = BCCD_data.get_image(i)
  draw = ImageDraw.Draw(img)
  classes = outputs[0]['labels'].cpu().numpy()
  scores = outputs[0]['scores'].detach().cpu().numpy()
  boxes = outputs[0]['boxes'].detach().cpu().numpy()
  for j,box in enumerate(boxes):
    if scores[j] > 0.5 :
      c = classes[j]
      c = c if c < 4 else 0
      #{'background': 0, 'RBC'(эритроциты): 1, 'Platelets (тромбоциты)': 2, 'WBC' (лейкоциты): 3}
      cl =     ['black', 'red',    'green','blue'] #названия цветов для предсказанных рамок
      clmark = ['black', 'orange', 'lime', 'cyan'] #названия цветов для размеченных рамок
      draw.rectangle(xy=box.tolist(), outline=cl[c], width = 2) #рисуем предсказанные рамки
      if j< len(BCCD_data[i][1]['boxes']): #предсказанных рамок может быть больше чем размеченных
        draw.rectangle(xy = BCCD_data[i][1]['boxes'][j].tolist(), outline = clmark[c]) #рисуем размеченные рамки
  plt.figure(figsize=(5, 5))
  plt.imshow(img)

"""#Вывод
Модель хорошо классифиирует эритроциты (красный жирный - размеченные, оранжевые - предсказанные рамки) и тромбоциты (зеленый жирный размеченные, салатовые - предсказанные рамки).
Но не очень хорошо определяет класс лейкоцито (должны быть синие жирные размеченные и голубые предсказанные рамки), а предсказывает почти везде оранжевый класс - как эритроциты, но расположение самих рамок близко к размеченным.
"""